{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "public_opticalFlow_NavigationNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDudmcRV7czb"
      },
      "source": [
        "#### **Void detection using optical flow and vanishing points voting**\n",
        "\n",
        "In this work, we rely on algorithms that ***extract vanishing points from a pair of images*** captured via a monocular camera. These points are ***voted using optical flow*** to ***estimate the furthest empty plane*** from the camera to which the linear trajectory from the quadcopter is free of obstacles. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1rJ8vTF5vADZwNEFQt16ox9MjS2wA2Mql\" width=\"600px\"/>\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Vn2PNxypcx"
      },
      "source": [
        "The void detection algorithm can be split into\n",
        "\n",
        "\n",
        "1.   Feature extraction\n",
        "2.   Optical flow extraciton and clustering\n",
        "3.   Vanishing point extraction\n",
        "4.   Vanish point voting\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1-NY6VPRw3nsQc79HcUCBdXsx1qXVPEbu\" width=\"1000px\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryV_eIE78ZkM"
      },
      "source": [
        "#### **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yvCIFlpv5i2",
        "outputId": "5b0ffc6c-ba1c-49d6-ed7a-5b486e789d66"
      },
      "source": [
        "# for SIFT features\n",
        "!pip install opencv-contrib-python==4.4.0.44"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==4.4.0.44 in /usr/local/lib/python3.7/dist-packages (4.4.0.44)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python==4.4.0.44) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fIOtx5bCBkT"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "import math\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn import metrics\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r5CUlsmCQNN",
        "outputId": "0319ff8e-e609-4cf8-845a-5b2825b3c969"
      },
      "source": [
        "cd /content/drive/My Drive/NavigationNet"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NavigationNet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BAjxhZ8mRy"
      },
      "source": [
        "#### **Initial parameters and functions**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MktossTiCCYT"
      },
      "source": [
        "# Parameters for lucas kanade optical flow\n",
        "lk_params = dict( winSize  = (15,15),\n",
        "                  maxLevel = 5,\n",
        "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMTD-AZUSGcy"
      },
      "source": [
        "#image grid for intesection computation\n",
        "side = 10\n",
        "w = 1280\n",
        "h = 720"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzZm7g8fsVK7"
      },
      "source": [
        "def reject_outliers_mask(data, m=2):\n",
        "    return abs(data - np.mean(data)) < m * np.std(data)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyQ41dltu_FJ"
      },
      "source": [
        "def reject_outliers(data,list1,list2,list3,m=1):\n",
        "  mask = reject_outliers_mask(data,m)\n",
        "  a = np.ma.compress_nd(np.ma.MaskedArray(list1, mask=~mask))\n",
        "  b = np.ma.compress_nd(np.ma.MaskedArray(list2, mask=~mask))\n",
        "  c = np.ma.compress_nd(np.ma.MaskedArray(list3, mask=~mask))\n",
        "  return a,b,c"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwPd28VGrFDo"
      },
      "source": [
        "def calculate_G_ab(side,w,h,m_list,c_list,angle_list):  \n",
        "  G_ab = np.zeros((int(h/side),int(w/side)))\n",
        "  for idx,(a,b,theta) in enumerate(zip(m_list,c_list,angle_list)):\n",
        "    for (c,d,gamma) in zip(m_list[(idx+1):len(m_list)],\n",
        "                          c_list[(idx+1):len(m_list)],\n",
        "                          angle_list[(idx+1):len(m_list)]):\n",
        "      if (theta>155):\n",
        "        theta = theta-180     \n",
        "      if abs(theta-gamma) < 15 and abs(theta-gamma) > 5: \n",
        "        x = (d-b)/(a-c)\n",
        "        y = a*x+b\n",
        "        if x >= 0 and x < w and y >= 0 and y < h:\n",
        "            G_ab[int(y/side),int(x/side)] = G_ab[int(y/side),int(x/side)] + 1\n",
        "  return G_ab"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeWFelivrJj5"
      },
      "source": [
        "def auto_canny(image, sigma=0.33):\n",
        "\t# compute the median of the single channel pixel intensities\n",
        "\tv = np.median(image)\n",
        "\t# apply automatic Canny edge detection using the computed median\n",
        "\tlower = int(max(0, (1.0 - sigma) * v))\n",
        "\tupper = int(min(255, (1.0 + sigma) * v))\n",
        "\tedged = cv.Canny(image, lower, upper)\n",
        "\t# return the edged image\n",
        "\treturn edged"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IizdOAeqK6jW"
      },
      "source": [
        "def img_reading(img1_o,img2_o):\n",
        "  img1 = cv.cvtColor(img1_o,cv.COLOR_BGR2GRAY)\n",
        "  img2 = cv.cvtColor(img2_o,cv.COLOR_BGR2GRAY)\n",
        "  return img1,img2"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66TglqSTLPT5"
      },
      "source": [
        "def feature_extraction(img1,img2):\n",
        "  # initiate detector\n",
        "  extractor = cv.xfeatures2d.SIFT_create(nOctaveLayers=3)\n",
        "  # find the keypoints and descriptors\n",
        "  kp1, des1 = extractor.detectAndCompute(img1,None)\n",
        "  kp2, des2 = extractor.detectAndCompute(img2,None)  \n",
        "  # create array of feature points in img1\n",
        "  pt0 = [m.pt for m in kp1]\n",
        "  pt0 = np.float32(pt0).reshape(-1,1,2)\n",
        "  return pt0"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKzS66W1Lszb"
      },
      "source": [
        "def compute_OF(img1,img2,pt0):\n",
        "  # calculate optical flow\n",
        "  p1, st, err = cv.calcOpticalFlowPyrLK(img1, img2, pt0, None, **lk_params)\n",
        "  # calculate inverse optical flow\n",
        "  p0r, _st, _err = cv.calcOpticalFlowPyrLK(img2, img1, p1, None, **lk_params)\n",
        "  # validate optical flow to inverse flow\n",
        "  d = abs(pt0-p0r).reshape(-1, 2).max(-1)\n",
        "  good = d < 0.05\n",
        "  # select good points\n",
        "  good_new = p1[good==1]\n",
        "  good_old = pt0[good==1]\n",
        "\n",
        "  # create array of c and m coefficients of the lines (y = m*x + c)\n",
        "  angle = []\n",
        "  magnitude = []\n",
        "  for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
        "    a,b = new.ravel()\n",
        "    c,d = old.ravel()\n",
        "    m = math.degrees(math.sqrt(pow(d-b,2)+pow(a-c,2)))\n",
        "    a = math.degrees(math.atan2((b-d),(c-a)))\n",
        "    if a < 0:\n",
        "      a = a + 360\n",
        "    angle.append(a)\n",
        "    magnitude.append(m)\n",
        "  return good_old,good_new,angle,magnitude"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8qPLK1LMSPF"
      },
      "source": [
        "def magnitude_filter(angle,magnitude,good_old,good_new):\n",
        "  # define number of itens to be eliminated\n",
        "  k = int(len(magnitude)*0.1)\n",
        "  # create array of ordered magnitude vectors\n",
        "  idx = np.argpartition(magnitude,k)\n",
        "  # mask to remove the bigger 10% magnitude OF vectors\n",
        "  mask = np.ones_like(magnitude, dtype=bool)\n",
        "  mask[idx[:k]] = False\n",
        "  magnitude_MagValid = np.ma.compress_nd(np.ma.MaskedArray(magnitude, mask=~mask))\n",
        "  x_new_MagValid = np.ma.compress_nd(np.ma.MaskedArray(good_new.reshape(-1,2)[:,0], \n",
        "                                                      mask=~mask))\n",
        "  y_new_MagValid = np.ma.compress_nd(np.ma.MaskedArray(good_new.reshape(-1,2)[:,1], \n",
        "                                                      mask=~mask))\n",
        "  angle_MagValid = np.ma.compress_nd(np.ma.MaskedArray(angle, mask=~mask))\n",
        "  return x_new_MagValid, y_new_MagValid, magnitude_MagValid, angle_MagValid"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfriRQMGNV3L"
      },
      "source": [
        "def choose_sigma(angle_MagValid):\n",
        "  # create vector to hold the number of filtered angles\n",
        "  sum_mask = []\n",
        "  # stop criteria: 0.05% of previous number of filtered vectors\n",
        "  for i in range(1,10):\n",
        "    mask = reject_outliers_mask(angle_MagValid,i)\n",
        "    s = np.sum(mask)  \n",
        "    sum_mask.append(s)\n",
        "    if i > 1:\n",
        "      if (s-sum_mask[-2]) < 0.05*sum_mask[-2]:\n",
        "        sigma = i  \n",
        "        break\n",
        "  return sigma"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFCBYFwhOFtN"
      },
      "source": [
        "def angular_filter(x_new_MagValid, y_new_MagValid, magnitude_MagValid, angle_MagValid):  \n",
        "  # decision of sigma value of poisson sigma parameter \n",
        "  sigma = 2 #choose_sigma(angle_MagValid)\n",
        "  # mask and angle poisson filtering\n",
        "  mask = reject_outliers_mask(angle_MagValid,sigma)\n",
        "  magnitudeValid = np.ma.compress_nd(np.ma.MaskedArray(magnitude_MagValid, \n",
        "                                                       mask=~mask))\n",
        "  angleValid = np.ma.compress_nd(np.ma.MaskedArray(angle_MagValid, mask=~mask))\n",
        "  xValid = np.ma.compress_nd(np.ma.MaskedArray(x_new_MagValid, mask=~mask))\n",
        "  yValid = np.ma.compress_nd(np.ma.MaskedArray(y_new_MagValid, mask=~mask))\n",
        "  return xValid,yValid,angleValid,magnitudeValid"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxuoITZaPXil"
      },
      "source": [
        "def choose_n(X):\n",
        "  calinski = []\n",
        "  davies = []\n",
        "  # range of calinski + davies-bouldin test\n",
        "  K = range(2, 16)\n",
        "  for k in K:\n",
        "      # Building and fitting the model\n",
        "      kmeanModel = KMeans(n_clusters=k,random_state=1).fit(X)\n",
        "      kmeanModel.fit(X)\n",
        "      labels = kmeanModel.labels_ \n",
        "      # calculating index\n",
        "      calinski.append(metrics.calinski_harabasz_score(X, labels))\n",
        "      davies.append(metrics.davies_bouldin_score(X, labels))\n",
        "  # get number of cluster for bigger calinski and lower davies-bouldin\n",
        "  n_clusters = 2 + np.argmax(np.array([i / j for i, j in zip(calinski, davies)]),\n",
        "                            axis=None)\n",
        "  return n_clusters"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxuDVHYgP0Ym"
      },
      "source": [
        "def clustering(X):\n",
        "  n_clusters = 12 #choose_n(X)\n",
        "  kmeans = KMeans(n_clusters = n_clusters, \n",
        "                  max_iter = 200).fit(X) \n",
        "  pred_y = kmeans.fit_predict(X) \n",
        "  return kmeans,pred_y,n_clusters"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2-aIXxNVG_3"
      },
      "source": [
        "def choose_k(dataset,kmeans,n_clusters):\n",
        "  mean_value = []\n",
        "  # decision of k value of k neareast neighbors\n",
        "  # stop criteria: 0.1% of previous estimated magnitudes\n",
        "  for i in range(5, 100, 5):   \n",
        "      knn = NearestNeighbors(n_neighbors=i) \n",
        "      knn.fit(dataset[:,0:2])\n",
        "      idx = knn.kneighbors(kmeans.cluster_centers_[:,0:2].reshape(-1,2),\n",
        "                          return_distance=False)\n",
        "      m = np.array(np.mean(dataset[idx,3],axis=1))\n",
        "      mean_value = np.append(mean_value,m,axis=0) \n",
        "      if i > 5:\n",
        "        div = [i / j for i, j in zip(mean_value.reshape(-1, n_clusters)[-2,:] - m,\n",
        "                                  mean_value.reshape(-1, n_clusters)[-2,:])]\n",
        "        if div[np.argmax(np.array(div), axis=None)] < 0.1:\n",
        "          n_neighbors = i\n",
        "          break\n",
        "  return n_neighbors"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JqjP0lxWgva"
      },
      "source": [
        "def NN(dataset,kmeans,n_clusters):\n",
        "  n_neighbors = 10 #choose_k(dataset,kmeans,n_clusters)\n",
        "  # fit nearest neighbors for each cluster center for optimal k\n",
        "  knn = NearestNeighbors(n_neighbors=n_neighbors)\n",
        "  knn.fit(dataset[:,0:2])\n",
        "  kmeans_cluster_centers_mag = np.zeros((n_clusters,1))\n",
        "  for i in range(0,n_clusters):\n",
        "    idx = knn.kneighbors(kmeans.cluster_centers_[i,0:2].reshape(-1,2), return_distance=False)\n",
        "    kmeans_cluster_centers_mag[i] = np.mean(dataset[idx.reshape(-1),3])\n",
        "  \n",
        "  # getting center of lowest magnitude (furtherst plane)\n",
        "  of_idx = np.argmin(kmeans_cluster_centers_mag, axis=None)\n",
        "  of_min_x = kmeans.cluster_centers_[of_idx,0]\n",
        "  of_min_y = kmeans.cluster_centers_[of_idx,1]\n",
        "\n",
        "  return n_neighbors,kmeans_cluster_centers_mag,of_idx,of_min_x,of_min_y,knn"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meomxMBCbir5"
      },
      "source": [
        "def pre_VP_extracting(img2):\n",
        "  cropped = img2[int(h/2):h,0:w]\n",
        "  # gaussian filter for canny transformation processing\n",
        "  blurred = cv.GaussianBlur(img2, (5, 5), 0)\n",
        "  # canny edge filter\n",
        "  edges = auto_canny(blurred,sigma=0.33)\n",
        "  # line recognition via hough transform\n",
        "  lines = cv.HoughLinesP(edges,rho = 1,theta = np.pi/180,\n",
        "                        threshold = 100,minLineLength = 50,\n",
        "                        maxLineGap = 10)\n",
        "  return lines"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5j2PjZikQ3F"
      },
      "source": [
        "def VP_extracting(lines,n_clusters,kmeans):\n",
        "  boundary = 40\n",
        "  angle=[]\n",
        "  # calculate, store and plot lines\n",
        "  for idx,(x1,y1,x2,y2) in enumerate(lines.reshape(-1,4)):\n",
        "      if x1 == x2: continue # pure horizontal lines\n",
        "      elif y1 == y2: continue # pure vertical lines\n",
        "      elif y1 < int(h/2) or y2 < int(h/2): continue # pure vertical lines\n",
        "      else: \n",
        "        angle_l = math.degrees(math.atan2((y2-y1),(x2-x1)))\n",
        "        if angle_l < 0:\n",
        "          angle_l = angle_l + 360\n",
        "          angle_wrap = angle_l - 180\n",
        "        else:\n",
        "          angle_wrap = angle_l\n",
        "        if angle_wrap>boundary and angle_wrap<(180-boundary) and abs(angle_wrap-90)>10:\n",
        "          A = np.vstack([(x1,x2),np.ones(len((x1,x2)))]).T\n",
        "          m, c = np.linalg.lstsq(A, (y1,y2))[0]      \n",
        "          x_y0 = int(-c/m)\n",
        "          x_yh = int((h-c)/m)\n",
        "          x_mean = (x1+x2)/2\n",
        "          y_mean = (y1+y2)/2\n",
        "          if lines.shape[0] > 100:\n",
        "            x_diff = kmeans.cluster_centers_[:,0] - np.ones((1,n_clusters))*x_mean\n",
        "            y_diff = kmeans.cluster_centers_[:,1] - np.ones((1,n_clusters))*y_mean\n",
        "            r = np.sqrt(x_diff*x_diff + y_diff*y_diff)  \n",
        "            idx = np.argmin(r, axis=None)\n",
        "          else:\n",
        "            idx = 0;\n",
        "          name = \"list_\"+str(idx)\n",
        "          n = [m,c,angle_wrap]\n",
        "          globals()[name] = np.append(globals()[name],n,axis=0) "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMIwd7s7mB6N"
      },
      "source": [
        "def compute_Gab(n_clusters): \n",
        "  # initialize variables\n",
        "  G_ab = np.zeros((int(h/side),int(w/side),n_clusters))\n",
        "\n",
        "  # compute greatest intersection point\n",
        "  for i in range(0,n_clusters):\n",
        "    name = \"list_\"+str(i)\n",
        "    G_ab[:,:,i] = calculate_G_ab(side,w,h,\n",
        "                                globals()[name][:,0],globals()[name][:,1],\n",
        "                                globals()[name][:,2])\n",
        "  return G_ab"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBQqO5iFmY0O"
      },
      "source": [
        "def result(G_ab,kmeans,kmeans_cluster_centers_mag,of_idx,of_min_x,of_min_y,n_clusters,knn,dataset):\n",
        "  dist = np.ones(n_clusters)*100\n",
        "  valid = np.ones(n_clusters)\n",
        "  for i in range(0,n_clusters): \n",
        "    # get pixel coordinates of VP point plane cantidate\n",
        "    y_idx,x_idx = np.unravel_index(np.argmax(G_ab[:,:,i], axis=None),\n",
        "                                    G_ab[:,:,i].shape)\n",
        "    if (y_idx or x_idx): \n",
        "      # if vanishing point is not out of image\n",
        "      x = int((x_idx+1.5)*side)\n",
        "      y = int((y_idx+1.5)*side)\n",
        "      dist[i] = math.hypot((int(of_min_y)-y), (int(of_min_x)-x))\n",
        "    else: \n",
        "      valid[i] = 100\n",
        "\n",
        "  # select nearest VP to OF cluster center\n",
        "  nearest_VP = np.argmin(np.array(np.multiply(dist,valid)))\n",
        "  # get pixel coordinates nearest VP to OF cluster center\n",
        "  y_idx,x_idx = np.unravel_index(np.argmax(G_ab[:,:,nearest_VP], axis=None),\n",
        "                                G_ab[:,:,nearest_VP].shape)\n",
        "  x = int((x_idx+1.5)*side)\n",
        "  y = int((y_idx+1.5)*side)\n",
        "  for i in range(0,n_clusters): \n",
        "    # get distance of nearest VP to all cluster centers\n",
        "    dist[i] = math.hypot((int(kmeans.cluster_centers_[i,1])-y), \n",
        "                        (int(kmeans.cluster_centers_[i,0])-x))\n",
        "  # get magnitude for VP\n",
        "  nearest_VP_mag_idx = knn.kneighbors(np.array(((x+of_min_x)/2,\n",
        "                                                (y+of_min_y)/2)).reshape(-1,2), \n",
        "                                      return_distance=False)\n",
        "  nearest_VP_mag = np.mean(dataset[nearest_VP_mag_idx.reshape(-1),3])\n",
        "  if abs(kmeans_cluster_centers_mag[of_idx]-nearest_VP_mag) < 0.05*kmeans_cluster_centers_mag[of_idx]:\n",
        "    print(\"VP valid\")\n",
        "  else:\n",
        "    print(\"VP not valid\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rmx9s35NhRr"
      },
      "source": [
        "def main(img1_o,img2_o):\n",
        "\n",
        "  ######################\n",
        "  ### pre processing ###\n",
        "  ######################\n",
        "  # convert images to greyscale\n",
        "  img1,img2 = img_reading(img1_o,img2_o)   \n",
        "  # create array of feature points in img1\n",
        "  pt0 = feature_extraction(img1,img2)\n",
        "  \n",
        "  ####################\n",
        "  ### optical flow ###\n",
        "  ####################\n",
        "  # calculate optical flow\n",
        "  good_old,good_new,angle,magnitude = compute_OF(img1,img2,pt0)  \n",
        "  # remove the bigger 10% magnitude OF vectors\n",
        "  x_new_MagValid,y_new_MagValid,magnitude_MagValid,angle_MagValid = magnitude_filter(angle,magnitude,good_old,good_new)\n",
        "  # angle poisson filtering\n",
        "  xValid,yValid,angleValid,magnitudeValid = angular_filter(x_new_MagValid, y_new_MagValid, magnitude_MagValid, angle_MagValid)  \n",
        "  # identify if OF number filtered features is valid\n",
        "  if len(xValid) > 100:\n",
        "    print(\"OF identified\")\n",
        "  else:\n",
        "    print(\"OF points NOT enough\")\n",
        "    breakpoint()  \n",
        "  # creating datasets for unsupervisioned training\n",
        "  dataset = np.array(list(zip(xValid, yValid,angleValid,\n",
        "                              magnitudeValid))).reshape(len(xValid), 4)  \n",
        "  # clustering\n",
        "  kmeans,pred_y,n_clusters = clustering(dataset[:,0:3])\n",
        "  # knn for clusters centers magnitude\n",
        "  n_neighbors,kmeans_cluster_centers_mag,of_idx,of_min_x,of_min_y,knn = NN(dataset,kmeans,n_clusters)\n",
        "  # identify if the drone is not in front of wall\n",
        "  if abs(np.std(kmeans_cluster_centers_mag)) >= 500:\n",
        "        print(\"Multiple planes available\")\n",
        "  else:\n",
        "    print(\"Multiple planes NOT available\")\n",
        "    breakpoint()\n",
        "  #####################\n",
        "  ### VP extracting ###\n",
        "  #####################\n",
        "  # VP extracting Hough Lines\n",
        "  lines = pre_VP_extracting(img2)\n",
        "  # create n_clustered lists for m, c and angle of line\n",
        "  for i in range(0,n_clusters):\n",
        "    name = \"list_\"+str(i)\n",
        "    globals()[name] = [0., 0., 0.]\n",
        "  VP_extracting(lines,n_clusters,kmeans)\n",
        "  # reorganize lists in 3 columns shape\n",
        "  for i in range(0,n_clusters):\n",
        "    name = \"list_\"+str(i)\n",
        "    globals()[name] = np.array(globals()[name]).reshape(-1,3)\n",
        "    globals()[name] = globals()[name][1:-1,:]\n",
        "  G_ab = compute_Gab(n_clusters)\n",
        "  result(G_ab,kmeans,kmeans_cluster_centers_mag,of_idx,of_min_x,of_min_y,n_clusters,knn,dataset)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s76sS2y8yQn"
      },
      "source": [
        "#### **Run**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqo0lbDD59Ol"
      },
      "source": [
        "img1_o = cv.imread('./9_9_FRONT_LEFT.png') # queryImage\n",
        "img2_o = cv.imread('./9_10_FRONT_LEFT.png') # trainImage"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJil_10Wf8TQ",
        "outputId": "565ae386-ac13-463d-ae18-a13a07b45579"
      },
      "source": [
        "main(img1_o,img2_o)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OF identified\n",
            "Multiple planes available\n",
            "VP valid\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}